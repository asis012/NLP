{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N-gram modelling\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#markoc chains = chains of different state\n",
    "\n",
    "text = \"\"\"Climate change again hello as  the name suggests refers to the changes in the global climate which result from the increasing average global temperature.  For example , changes in precipitation patterns , increased prevalence of droughts, heat waves, and other extreme weather, etc.  These projections of future global precipitation changes from the 2007 IPCC report are an example of climate change\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n =6\n",
    "ngrams = {}\n",
    "len(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Climat': ['e'],\n",
       " 'limate': [' ', ' ', ' '],\n",
       " 'imate ': ['c', 'w', 'c'],\n",
       " 'mate c': ['h', 'h'],\n",
       " 'ate ch': ['a', 'a'],\n",
       " 'te cha': ['n', 'n'],\n",
       " 'e chan': ['g', 'g', 'g'],\n",
       " ' chang': ['e', 'e', 'e', 'e', 'e'],\n",
       " 'change': [' ', 's', 's', 's', '\\n'],\n",
       " 'hange ': ['a'],\n",
       " 'ange a': ['g'],\n",
       " 'nge ag': ['a'],\n",
       " 'ge aga': ['i'],\n",
       " 'e agai': ['n'],\n",
       " ' again': [' '],\n",
       " 'again ': ['h'],\n",
       " 'gain h': ['e'],\n",
       " 'ain he': ['l'],\n",
       " 'in hel': ['l'],\n",
       " 'n hell': ['o'],\n",
       " ' hello': [' '],\n",
       " 'hello ': ['a'],\n",
       " 'ello a': ['s'],\n",
       " 'llo as': [' '],\n",
       " 'lo as ': [' '],\n",
       " 'o as  ': ['t'],\n",
       " ' as  t': ['h'],\n",
       " 'as  th': ['e'],\n",
       " 's  the': [' '],\n",
       " '  the ': ['n'],\n",
       " ' the n': ['a'],\n",
       " 'the na': ['m'],\n",
       " 'he nam': ['e'],\n",
       " 'e name': [' '],\n",
       " ' name ': ['s'],\n",
       " 'name s': ['u'],\n",
       " 'ame su': ['g'],\n",
       " 'me sug': ['g'],\n",
       " 'e sugg': ['e'],\n",
       " ' sugge': ['s'],\n",
       " 'sugges': ['t'],\n",
       " 'uggest': ['s'],\n",
       " 'ggests': [' '],\n",
       " 'gests ': ['r'],\n",
       " 'ests r': ['e'],\n",
       " 'sts re': ['f'],\n",
       " 'ts ref': ['e'],\n",
       " 's refe': ['r'],\n",
       " ' refer': ['s'],\n",
       " 'refers': [' '],\n",
       " 'efers ': ['t'],\n",
       " 'fers t': ['o'],\n",
       " 'ers to': [' '],\n",
       " 'rs to ': ['t'],\n",
       " 's to t': ['h'],\n",
       " ' to th': ['e'],\n",
       " 'to the': [' '],\n",
       " 'o the ': ['c'],\n",
       " ' the c': ['h'],\n",
       " 'the ch': ['a'],\n",
       " 'he cha': ['n'],\n",
       " 'hanges': [' ', ' ', ' '],\n",
       " 'anges ': ['i', 'i', 'f'],\n",
       " 'nges i': ['n', 'n'],\n",
       " 'ges in': [' ', ' '],\n",
       " 'es in ': ['t', 'p'],\n",
       " 's in t': ['h'],\n",
       " ' in th': ['e'],\n",
       " 'in the': [' '],\n",
       " 'n the ': ['g'],\n",
       " ' the g': ['l'],\n",
       " 'the gl': ['o'],\n",
       " 'he glo': ['b'],\n",
       " 'e glob': ['a', 'a', 'a'],\n",
       " ' globa': ['l', 'l', 'l'],\n",
       " 'global': [' ', ' ', ' '],\n",
       " 'lobal ': ['c', 't', 'p'],\n",
       " 'obal c': ['l'],\n",
       " 'bal cl': ['i'],\n",
       " 'al cli': ['m'],\n",
       " 'l clim': ['a'],\n",
       " ' clima': ['t', 't'],\n",
       " 'climat': ['e', 'e'],\n",
       " 'mate w': ['h'],\n",
       " 'ate wh': ['i'],\n",
       " 'te whi': ['c'],\n",
       " 'e whic': ['h'],\n",
       " ' which': [' '],\n",
       " 'which ': ['r'],\n",
       " 'hich r': ['e'],\n",
       " 'ich re': ['s'],\n",
       " 'ch res': ['u'],\n",
       " 'h resu': ['l'],\n",
       " ' resul': ['t'],\n",
       " 'result': [' '],\n",
       " 'esult ': ['f'],\n",
       " 'sult f': ['r'],\n",
       " 'ult fr': ['o'],\n",
       " 'lt fro': ['m'],\n",
       " 't from': [' '],\n",
       " ' from ': ['t', 't'],\n",
       " 'from t': ['h', 'h'],\n",
       " 'rom th': ['e', 'e'],\n",
       " 'om the': [' ', ' '],\n",
       " 'm the ': ['i', '2'],\n",
       " ' the i': ['n'],\n",
       " 'the in': ['c'],\n",
       " 'he inc': ['r'],\n",
       " 'e incr': ['e'],\n",
       " ' incre': ['a', 'a'],\n",
       " 'increa': ['s', 's'],\n",
       " 'ncreas': ['i', 'e'],\n",
       " 'creasi': ['n'],\n",
       " 'reasin': ['g'],\n",
       " 'easing': [' '],\n",
       " 'asing ': ['a'],\n",
       " 'sing a': ['v'],\n",
       " 'ing av': ['e'],\n",
       " 'ng ave': ['r'],\n",
       " 'g aver': ['a'],\n",
       " ' avera': ['g'],\n",
       " 'averag': ['e'],\n",
       " 'verage': [' '],\n",
       " 'erage ': ['g'],\n",
       " 'rage g': ['l'],\n",
       " 'age gl': ['o'],\n",
       " 'ge glo': ['b'],\n",
       " 'obal t': ['e'],\n",
       " 'bal te': ['m'],\n",
       " 'al tem': ['p'],\n",
       " 'l temp': ['e'],\n",
       " ' tempe': ['r'],\n",
       " 'temper': ['a'],\n",
       " 'empera': ['t'],\n",
       " 'mperat': ['u'],\n",
       " 'peratu': ['r'],\n",
       " 'eratur': ['e'],\n",
       " 'rature': ['.'],\n",
       " 'ature.': [' '],\n",
       " 'ture. ': [' '],\n",
       " 'ure.  ': ['F'],\n",
       " 're.  F': ['o'],\n",
       " 'e.  Fo': ['r'],\n",
       " '.  For': [' '],\n",
       " '  For ': ['e'],\n",
       " ' For e': ['x'],\n",
       " 'For ex': ['a'],\n",
       " 'or exa': ['m'],\n",
       " 'r exam': ['p'],\n",
       " ' examp': ['l', 'l'],\n",
       " 'exampl': ['e', 'e'],\n",
       " 'xample': [' ', ' '],\n",
       " 'ample ': [',', 'o'],\n",
       " 'mple ,': [' '],\n",
       " 'ple , ': ['c'],\n",
       " 'le , c': ['h'],\n",
       " 'e , ch': ['a'],\n",
       " ' , cha': ['n'],\n",
       " ', chan': ['g'],\n",
       " 's in p': ['r'],\n",
       " ' in pr': ['e'],\n",
       " 'in pre': ['c'],\n",
       " 'n prec': ['i'],\n",
       " ' preci': ['p', 'p'],\n",
       " 'precip': ['i', 'i'],\n",
       " 'recipi': ['t', 't'],\n",
       " 'ecipit': ['a', 'a'],\n",
       " 'cipita': ['t', 't'],\n",
       " 'ipitat': ['i', 'i'],\n",
       " 'pitati': ['o', 'o'],\n",
       " 'itatio': ['n', 'n'],\n",
       " 'tation': [' ', ' '],\n",
       " 'ation ': ['p', 'c'],\n",
       " 'tion p': ['a'],\n",
       " 'ion pa': ['t'],\n",
       " 'on pat': ['t'],\n",
       " 'n patt': ['e'],\n",
       " ' patte': ['r'],\n",
       " 'patter': ['n'],\n",
       " 'attern': ['s'],\n",
       " 'tterns': [' '],\n",
       " 'terns ': [','],\n",
       " 'erns ,': [' '],\n",
       " 'rns , ': ['i'],\n",
       " 'ns , i': ['n'],\n",
       " 's , in': ['c'],\n",
       " ' , inc': ['r'],\n",
       " ', incr': ['e'],\n",
       " 'crease': ['d'],\n",
       " 'reased': [' '],\n",
       " 'eased ': ['p'],\n",
       " 'ased p': ['r'],\n",
       " 'sed pr': ['e'],\n",
       " 'ed pre': ['v'],\n",
       " 'd prev': ['a'],\n",
       " ' preva': ['l'],\n",
       " 'preval': ['e'],\n",
       " 'revale': ['n'],\n",
       " 'evalen': ['c'],\n",
       " 'valenc': ['e'],\n",
       " 'alence': [' '],\n",
       " 'lence ': ['o'],\n",
       " 'ence o': ['f'],\n",
       " 'nce of': [' '],\n",
       " 'ce of ': ['d'],\n",
       " 'e of d': ['r'],\n",
       " ' of dr': ['o'],\n",
       " 'of dro': ['u'],\n",
       " 'f drou': ['g'],\n",
       " ' droug': ['h'],\n",
       " 'drough': ['t'],\n",
       " 'rought': ['s'],\n",
       " 'oughts': [','],\n",
       " 'ughts,': [' '],\n",
       " 'ghts, ': ['h'],\n",
       " 'hts, h': ['e'],\n",
       " 'ts, he': ['a'],\n",
       " 's, hea': ['t'],\n",
       " ', heat': [' '],\n",
       " ' heat ': ['w'],\n",
       " 'heat w': ['a'],\n",
       " 'eat wa': ['v'],\n",
       " 'at wav': ['e'],\n",
       " 't wave': ['s'],\n",
       " ' waves': [','],\n",
       " 'waves,': [' '],\n",
       " 'aves, ': ['a'],\n",
       " 'ves, a': ['n'],\n",
       " 'es, an': ['d'],\n",
       " 's, and': [' '],\n",
       " ', and ': ['o'],\n",
       " ' and o': ['t'],\n",
       " 'and ot': ['h'],\n",
       " 'nd oth': ['e'],\n",
       " 'd othe': ['r'],\n",
       " ' other': [' '],\n",
       " 'other ': ['e'],\n",
       " 'ther e': ['x'],\n",
       " 'her ex': ['t'],\n",
       " 'er ext': ['r'],\n",
       " 'r extr': ['e'],\n",
       " ' extre': ['m'],\n",
       " 'extrem': ['e'],\n",
       " 'xtreme': [' '],\n",
       " 'treme ': ['w'],\n",
       " 'reme w': ['e'],\n",
       " 'eme we': ['a'],\n",
       " 'me wea': ['t'],\n",
       " 'e weat': ['h'],\n",
       " ' weath': ['e'],\n",
       " 'weathe': ['r'],\n",
       " 'eather': [','],\n",
       " 'ather,': [' '],\n",
       " 'ther, ': ['e'],\n",
       " 'her, e': ['t'],\n",
       " 'er, et': ['c'],\n",
       " 'r, etc': ['.'],\n",
       " ', etc.': [' '],\n",
       " ' etc. ': [' '],\n",
       " 'etc.  ': ['T'],\n",
       " 'tc.  T': ['h'],\n",
       " 'c.  Th': ['e'],\n",
       " '.  The': ['s'],\n",
       " '  Thes': ['e'],\n",
       " ' These': [' '],\n",
       " 'These ': ['p'],\n",
       " 'hese p': ['r'],\n",
       " 'ese pr': ['o'],\n",
       " 'se pro': ['j'],\n",
       " 'e proj': ['e'],\n",
       " ' proje': ['c'],\n",
       " 'projec': ['t'],\n",
       " 'roject': ['i'],\n",
       " 'ojecti': ['o'],\n",
       " 'jectio': ['n'],\n",
       " 'ection': ['s'],\n",
       " 'ctions': [' '],\n",
       " 'tions ': ['o'],\n",
       " 'ions o': ['f'],\n",
       " 'ons of': [' '],\n",
       " 'ns of ': ['f'],\n",
       " 's of f': ['u'],\n",
       " ' of fu': ['t'],\n",
       " 'of fut': ['u'],\n",
       " 'f futu': ['r'],\n",
       " ' futur': ['e'],\n",
       " 'future': [' '],\n",
       " 'uture ': ['g'],\n",
       " 'ture g': ['l'],\n",
       " 'ure gl': ['o'],\n",
       " 're glo': ['b'],\n",
       " 'obal p': ['r'],\n",
       " 'bal pr': ['e'],\n",
       " 'al pre': ['c'],\n",
       " 'l prec': ['i'],\n",
       " 'tion c': ['h'],\n",
       " 'ion ch': ['a'],\n",
       " 'on cha': ['n'],\n",
       " 'n chan': ['g'],\n",
       " 'nges f': ['r'],\n",
       " 'ges fr': ['o'],\n",
       " 'es fro': ['m'],\n",
       " 's from': [' '],\n",
       " ' the 2': ['0'],\n",
       " 'the 20': ['0'],\n",
       " 'he 200': ['7'],\n",
       " 'e 2007': [' '],\n",
       " ' 2007 ': ['I'],\n",
       " '2007 I': ['P'],\n",
       " '007 IP': ['C'],\n",
       " '07 IPC': ['C'],\n",
       " '7 IPCC': [' '],\n",
       " ' IPCC ': ['r'],\n",
       " 'IPCC r': ['e'],\n",
       " 'PCC re': ['p'],\n",
       " 'CC rep': ['o'],\n",
       " 'C repo': ['r'],\n",
       " ' repor': ['t'],\n",
       " 'report': [' '],\n",
       " 'eport ': ['a'],\n",
       " 'port a': ['r'],\n",
       " 'ort ar': ['e'],\n",
       " 'rt are': [' '],\n",
       " 't are ': ['a'],\n",
       " ' are a': ['n'],\n",
       " 'are an': [' '],\n",
       " 're an ': ['e'],\n",
       " 'e an e': ['x'],\n",
       " ' an ex': ['a'],\n",
       " 'an exa': ['m'],\n",
       " 'n exam': ['p'],\n",
       " 'mple o': ['f'],\n",
       " 'ple of': [' '],\n",
       " 'le of ': ['c'],\n",
       " 'e of c': ['l'],\n",
       " ' of cl': ['i'],\n",
       " 'of cli': ['m'],\n",
       " 'f clim': ['a']}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#character N-gram model\n",
    "for i in range(len(text)-6):\n",
    "    gram = text[i:i+n]\n",
    "    if gram not in ngrams.keys():\n",
    "        ngrams[gram] = []\n",
    "      \n",
    "    \n",
    "        \n",
    "    ngrams[gram].append(text[i+n])\n",
    "   \n",
    "\n",
    "    \n",
    "ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate change\n",
      "\n"
     ]
    }
   ],
   "source": [
    "currentgram = text[0:n]\n",
    "result = currentgram\n",
    "for i in range(100):\n",
    "    if currentgram not in ngrams.keys():\n",
    "        break\n",
    "    possibilities = ngrams[currentgram]\n",
    "    nextitem = possibilities[random.randrange(len(possibilities))]\n",
    "    result += nextitem\n",
    "    currentgram = result[len(result)-n:len(result)]  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibilities = ngrams[\"cli\"]\n",
    "# possibilities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word Ngram model\n",
    "n = 3\n",
    "ngrams = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'For example ,': ['changes', 'changes'],\n",
       " 'example , changes': ['in', 'in'],\n",
       " ', changes in': ['precipitation', 'precipitation'],\n",
       " 'changes in precipitation': ['patterns', 'patterns'],\n",
       " 'in precipitation patterns': [',', ','],\n",
       " 'precipitation patterns ,': ['increased', 'increased'],\n",
       " 'patterns , increased': ['prevalence', 'prevalence'],\n",
       " ', increased prevalence': ['of', 'of'],\n",
       " 'increased prevalence of': ['droughts', 'droughts'],\n",
       " 'prevalence of droughts': [',', ','],\n",
       " 'of droughts ,': ['heat', 'heat'],\n",
       " 'droughts , heat': ['waves', 'waves'],\n",
       " ', heat waves': [',', ','],\n",
       " 'heat waves ,': ['and', 'and'],\n",
       " 'waves , and': ['other', 'other'],\n",
       " ', and other': ['extreme', 'extreme'],\n",
       " 'and other extreme': ['weather', 'weather'],\n",
       " 'other extreme weather': [',', ','],\n",
       " 'extreme weather ,': ['etc', 'etc'],\n",
       " 'weather , etc': ['.', '.'],\n",
       " ', etc .': ['These', 'These'],\n",
       " 'etc . These': ['projections', 'projections'],\n",
       " '. These projections': ['of', 'of'],\n",
       " 'These projections of': ['future', 'future'],\n",
       " 'projections of future': ['global', 'global'],\n",
       " 'of future global': ['precipitation', 'precipitation'],\n",
       " 'future global precipitation': ['changes', 'changes'],\n",
       " 'global precipitation changes': ['from', 'from'],\n",
       " 'precipitation changes from': ['the', 'the'],\n",
       " 'changes from the': ['2007', '2007'],\n",
       " 'from the 2007': ['IPCC', 'IPCC'],\n",
       " 'the 2007 IPCC': ['report', 'report'],\n",
       " '2007 IPCC report': ['are', 'are'],\n",
       " 'IPCC report are': ['an', 'an'],\n",
       " 'report are an': ['example', 'example'],\n",
       " 'are an example': ['of', 'of'],\n",
       " 'an example of': ['climate', 'climate'],\n",
       " 'example of climate': ['change', 'change'],\n",
       " 'Climate change again': ['hello'],\n",
       " 'change again hello': ['as'],\n",
       " 'again hello as': ['the'],\n",
       " 'hello as the': ['name'],\n",
       " 'as the name': ['suggests'],\n",
       " 'the name suggests': ['refers'],\n",
       " 'name suggests refers': ['to'],\n",
       " 'suggests refers to': ['the'],\n",
       " 'refers to the': ['changes'],\n",
       " 'to the changes': ['in'],\n",
       " 'the changes in': ['the'],\n",
       " 'changes in the': ['global'],\n",
       " 'in the global': ['climate'],\n",
       " 'the global climate': ['which'],\n",
       " 'global climate which': ['result'],\n",
       " 'climate which result': ['from'],\n",
       " 'which result from': ['the'],\n",
       " 'result from the': ['increasing'],\n",
       " 'from the increasing': ['average'],\n",
       " 'the increasing average': ['global'],\n",
       " 'increasing average global': ['temperature'],\n",
       " 'average global temperature': ['.'],\n",
       " 'global temperature .': ['For'],\n",
       " 'temperature . For': ['example'],\n",
       " '. For example': [',']}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text)\n",
    "for i in range(len(words)-n):\n",
    "    gram = ' '.join(words[i:i+n])\n",
    "    if gram not in ngrams.keys():\n",
    "        ngrams[gram] = []\n",
    "    ngrams[gram].append(words[i+n])\n",
    "ngrams\n",
    "# if \"change again as\" not in ngrams.keys():\n",
    "#     print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate change again hello as the name suggests refers to the changes in the global climate which result from the increasing average global temperature . For example , changes in precipitation patterns ,\n"
     ]
    }
   ],
   "source": [
    "currentgram = ' '.join(words[0:n])\n",
    "\n",
    "result  = currentgram\n",
    "for i in range(30):\n",
    "    if currentgram not in ngrams.keys():\n",
    "        break\n",
    "    possibilities = ngrams[currentgram]\n",
    "    nextitem = possibilities[random.randrange(len(possibilities))]\n",
    "    result = result + ' ' + nextitem \n",
    "    rword = nltk.word_tokenize(result)\n",
    "    currentgram = ' '.join(rword[len(rword)-n:len(rword)])\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
