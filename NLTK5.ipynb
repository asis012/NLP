{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latent semantic analysis\n",
    "#SVD:  \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"The amount of polution is increasing day by day\",\n",
    "          \"The concert was just great\",\n",
    "          \"I look to see Gordon Ramsay cook\",\n",
    "          \"Google is introducing a new technology\",\n",
    "          \"AI robots are examples of great technology present today\",\n",
    "          \"All of us were singing in the concert\",\n",
    "          \"We have launch campings to stop pollution and global warming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [line.lower() for line in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the amount of polution is increasing day by day',\n",
       " 'the concert was just great',\n",
       " 'i look to see gordon ramsay cook',\n",
       " 'google is introducing a new technology',\n",
       " 'ai robots are examples of great technology present today',\n",
       " 'all of us were singing in the concert',\n",
       " 'we have launch campings to stop pollution and global warming']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 34)\t0.22786438777524437\n",
      "  (0, 2)\t0.3211483974289088\n",
      "  (0, 24)\t0.22786438777524437\n",
      "  (0, 26)\t0.3211483974289088\n",
      "  (0, 19)\t0.2665807498646048\n",
      "  (0, 17)\t0.3211483974289088\n",
      "  (0, 9)\t0.6422967948578177\n",
      "  (0, 5)\t0.3211483974289088\n"
     ]
    }
   ],
   "source": [
    "vector = TfidfVectorizer()\n",
    "x = vector.fit_transform(dataset)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=4, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=4,n_iter=100)\n",
    "lsa.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = lsa.components_\n",
    "row1\n",
    "\n",
    "concept_words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'all', 'amount', 'and', 'are', 'by', 'campings', 'concert', 'cook', 'day', 'examples', 'global', 'google', 'gordon', 'great', 'have', 'in', 'increasing', 'introducing', 'is', 'just', 'launch', 'look', 'new', 'of', 'pollution', 'polution', 'present', 'ramsay', 'robots', 'see', 'singing', 'stop', 'technology', 'the', 'to', 'today', 'us', 'warming', 'was', 'we', 'were']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Concept0': [('the', 0.3760982952926374),\n",
       "  ('concert', 0.34498873923306617),\n",
       "  ('great', 0.3001240258948741),\n",
       "  ('of', 0.29579806095266664),\n",
       "  ('just', 0.23736582929791233),\n",
       "  ('was', 0.23736582929791233),\n",
       "  ('day', 0.2289215954150445),\n",
       "  ('technology', 0.18383834567413432),\n",
       "  ('all', 0.17824025175628977),\n",
       "  ('in', 0.17824025175628977)],\n",
       " 'Concept1': [('to', 0.4157884439670068),\n",
       "  ('cook', 0.2835916579351076),\n",
       "  ('gordon', 0.2835916579351076),\n",
       "  ('look', 0.2835916579351076),\n",
       "  ('ramsay', 0.2835916579351076),\n",
       "  ('see', 0.2835916579351076),\n",
       "  ('and', 0.2173064471129244),\n",
       "  ('campings', 0.2173064471129244),\n",
       "  ('global', 0.2173064471129244),\n",
       "  ('have', 0.2173064471129244)],\n",
       " 'Concept2': [('technology', 0.37791806767144015),\n",
       "  ('is', 0.34196143806319834),\n",
       "  ('google', 0.3413969441909744),\n",
       "  ('introducing', 0.3413969441909744),\n",
       "  ('new', 0.3413969441909744),\n",
       "  ('day', 0.14112432680994713),\n",
       "  ('are', 0.11387892195373076),\n",
       "  ('examples', 0.11387892195373076),\n",
       "  ('present', 0.11387892195373076),\n",
       "  ('robots', 0.11387892195373076)],\n",
       " 'Concept3': [('day', 0.4654267679041107),\n",
       "  ('by', 0.23271338395205535),\n",
       "  ('increasing', 0.23271338395205535),\n",
       "  ('polution', 0.23271338395205535),\n",
       "  ('amount', 0.2327133839520553),\n",
       "  ('is', 0.2126445520245011),\n",
       "  ('the', 0.12724213180694388),\n",
       "  ('in', 0.056446647527265525),\n",
       "  ('singing', 0.056446647527265525),\n",
       "  ('us', 0.056446647527265525)]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = vector.get_feature_names()\n",
    "print(terms)\n",
    "for i,comp in enumerate(lsa.components_):\n",
    "    componentsterms = zip(terms,comp)\n",
    "    sortedterms = sorted(componentsterms,key=lambda x:x[1],reverse=True)\n",
    "    sortedterms = sortedterms[:10]\n",
    "    concept_words[\"Concept\" + str(i)] = sortedterms\n",
    "#     print(\"concept of\",i,\":\")\n",
    "#     for term in sortedterms:\n",
    "#         print(term)\n",
    "   # print(sortedterms)\n",
    "concept_words\n",
    "\n",
    "# for word_with_score in concept_words[key]:\n",
    "#     print(word_with_score[0])\n",
    "#     print(word_with_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concept0:\n",
      "1.129739547075393\n",
      "1.4959427190164023\n",
      "0\n",
      "0.18383834567413432\n",
      "0.7797604325216752\n",
      "1.37336559899095\n",
      "0\n",
      "\n",
      "Concept1:\n",
      "0\n",
      "0\n",
      "1.833746733642545\n",
      "0\n",
      "0\n",
      "0\n",
      "1.2850142324187046\n",
      "\n",
      "Concept2:\n",
      "0.6242100916830926\n",
      "0\n",
      "0\n",
      "1.7440703383075615\n",
      "0.8334337554863632\n",
      "0\n",
      "0\n",
      "\n",
      "Concept3:\n",
      "2.2015937554478877\n",
      "0.12724213180694388\n",
      "0\n",
      "0.2126445520245011\n",
      "0\n",
      "0.29658207438874046\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "for key in concept_words.keys():\n",
    "    sentence_score = []\n",
    "    for sentecne in dataset:\n",
    "        words = nltk.word_tokenize(sentecne)\n",
    "        score = 0\n",
    "        for word in words:\n",
    "            for word_with_score in concept_words[key]:\n",
    "                if word == word_with_score[0]:\n",
    "                    score = score + word_with_score[1]\n",
    "        sentence_score.append(score)\n",
    "    print(\"\\n\"+key+\":\")\n",
    "    for senetnce_word in sentence_score:\n",
    "        print(senetnce_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
