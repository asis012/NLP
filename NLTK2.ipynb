{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragaph = \"\"\"The authors are indebted to the following people for feedback on earlier drafts of this\n",
    "book: Doug Arnold, Michaela Atterer, Greg Aumann, Kenneth Beesley, Steven Bethard,\n",
    "Ondrej Bojar, Chris Cieri, Robin Cooper, Grev Corbett, James Curran, Dan Garrette,\n",
    "Jean Mark Gawron, Doug Hellmann, Nitin Indurkhya, Mark Liberman, Peter Ljunglöf,\n",
    "Stefan Müller, Robin Munn, Joel Nothman, Adam Przepiorkowski, Brandon Rhodes,\n",
    "Stuart Robinson, Jussi Salmela, Kyle Schlansker, Rob Speer, and Richard Sproat. We\n",
    "are thankful to many students and colleagues for their comments on the class materials\n",
    "that evolved into these chapters, including participants at NLP and linguistics summer\n",
    "schools in Brazil, India, and the USA. This book would not exist without the members\n",
    "of the nltk-dev developer community, named on the NLTK website, who have given\n",
    "so freely of their time and expertise in building and extending NLTK.\n",
    "We are grateful to the U.S. National Science Foundation, the Linguistic Data Consortium, an Edward Clarence Dyason Fellowship, and the Universities of Pennsylvania,\n",
    "Edinburgh, and Melbourne for supporting our work on this book.\n",
    "We thank Julie Steele, Abby Fox, Loranah Dimant, and the rest of the O’Reilly team,\n",
    "for organizing comprehensive reviews of our drafts from people across the NLP and\n",
    "Python communities, for cheerfully customizing O’Reilly’s production tools to accommodate our needs, and for meticulous copyediting work.\n",
    "Finally, we owe a huge debt of gratitude to our partners, Kay, Mimo, and Jee, for their\n",
    "love, patience, and support over the many years that we worked on this book. We hope\n",
    "that our children—Andrew, Alison, Kirsten, Leonie, and Maaike—catch our enthusiasm for language and computation from these pages.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The authors are indebted to the following people for feedback on earlier drafts of this\\nbook: Doug Arnold, Michaela Atterer, Greg Aumann, Kenneth Beesley, Steven Bethard,\\nOndrej Bojar, Chris Cieri, Robin Cooper, Grev Corbett, James Curran, Dan Garrette,\\nJean Mark Gawron, Doug Hellmann, Nitin Indurkhya, Mark Liberman, Peter Ljunglöf,\\nStefan Müller, Robin Munn, Joel Nothman, Adam Przepiorkowski, Brandon Rhodes,\\nStuart Robinson, Jussi Salmela, Kyle Schlansker, Rob Speer, and Richard Sproat.',\n",
       " 'We\\nare thankful to many students and colleagues for their comments on the class materials\\nthat evolved into these chapters, including participants at NLP and linguistics summer\\nschools in Brazil, India, and the USA.',\n",
       " 'This book would not exist without the members\\nof the nltk-dev developer community, named on the NLTK website, who have given\\nso freely of their time and expertise in building and extending NLTK.',\n",
       " 'We are grateful to the U.S. National Science Foundation, the Linguistic Data Consortium, an Edward Clarence Dyason Fellowship, and the Universities of Pennsylvania,\\nEdinburgh, and Melbourne for supporting our work on this book.',\n",
       " 'We thank Julie Steele, Abby Fox, Loranah Dimant, and the rest of the O’Reilly team,\\nfor organizing comprehensive reviews of our drafts from people across the NLP and\\nPython communities, for cheerfully customizing O’Reilly’s production tools to accommodate our needs, and for meticulous copyediting work.',\n",
       " 'Finally, we owe a huge debt of gratitude to our partners, Kay, Mimo, and Jee, for their\\nlove, patience, and support over the many years that we worked on this book.',\n",
       " 'We hope\\nthat our children—Andrew, Alison, Kirsten, Leonie, and Maaike—catch our enthusiasm for language and computation from these pages.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragaph)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = nltk.word_tokenize(sentences[0])\n",
    "#word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the author are indebt to the follow peopl for feedback on earlier draft of thi book : doug arnold , michaela atter , greg aumann , kenneth beesley , steven bethard , ondrej bojar , chri cieri , robin cooper , grev corbett , jame curran , dan garrett , jean mark gawron , doug hellmann , nitin indurkhya , mark liberman , peter ljunglöf , stefan müller , robin munn , joel nothman , adam przepiorkowski , brandon rhode , stuart robinson , jussi salmela , kyle schlansker , rob speer , and richard sproat .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "#fast but good in spam not spam detection\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    newwords = [stemmer.stem(word) for word in words]\n",
    "    sentences[i] = \" \".join(newwords)\n",
    "\n",
    "\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The author are indebted to the following people for feedback on earlier draft of this book : Doug Arnold , Michaela Atterer , Greg Aumann , Kenneth Beesley , Steven Bethard , Ondrej Bojar , Chris Cieri , Robin Cooper , Grev Corbett , James Curran , Dan Garrette , Jean Mark Gawron , Doug Hellmann , Nitin Indurkhya , Mark Liberman , Peter Ljunglöf , Stefan Müller , Robin Munn , Joel Nothman , Adam Przepiorkowski , Brandon Rhodes , Stuart Robinson , Jussi Salmela , Kyle Schlansker , Rob Speer , and Richard Sproat .'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemantization\n",
    "#slow but good in question anser examples\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "sentences = nltk.sent_tokenize(paragaph)\n",
    "lemmantizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    newwords = [lemmantizer.lemmatize(word) for word in word]\n",
    "    sentences[i] = ' '.join(newwords)\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The authors indebted following people feedback earlier drafts book : Doug Arnold , Michaela Atterer , Greg Aumann , Kenneth Beesley , Steven Bethard , Ondrej Bojar , Chris Cieri , Robin Cooper , Grev Corbett , James Curran , Dan Garrette , Jean Mark Gawron , Doug Hellmann , Nitin Indurkhya , Mark Liberman , Peter Ljunglöf , Stefan Müller , Robin Munn , Joel Nothman , Adam Przepiorkowski , Brandon Rhodes , Stuart Robinson , Jussi Salmela , Kyle Schlansker , Rob Speer , Richard Sproat .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords good in sentimental Analysis \n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "#sentences  = nltk.sent_tokenize(paragaph)\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    newwords = [word for word in words if word not in stopwords.words('english')]\n",
    "    sentences[i] = ' '.join(newwords)\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
